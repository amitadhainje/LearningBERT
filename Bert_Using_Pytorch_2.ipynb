{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert-Using-Pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPcAiy4J2tdqRd/d3k00aMn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amitadhainje/LearningBERT/blob/master/Bert_Using_Pytorch_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRBPb5jtDit7"
      },
      "source": [
        "!pip install -q -U watermark"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b669lbEDjxe"
      },
      "source": [
        "!pip install -qq transformers"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BWVItHaDlw4",
        "outputId": "bb90ec31-6f51-470d-bdda-a1a9c97ca59b"
      },
      "source": [
        "%reload_ext watermark\n",
        "%watermark -v -p numpy,pandas,torch,transformers"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python implementation: CPython\n",
            "Python version       : 3.7.11\n",
            "IPython version      : 5.5.0\n",
            "\n",
            "numpy       : 1.19.5\n",
            "pandas      : 1.1.5\n",
            "torch       : 1.9.0+cu102\n",
            "transformers: 4.9.2\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "m5XTP8QSDo-S",
        "outputId": "e04463c5-8125-4b3f-b39b-ed58ee6390c0"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d9842d6a-0b63-4e6b-9e40-19b730c60ecd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d9842d6a-0b63-4e6b-9e40-19b730c60ecd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": [
            "Saving reviews.csv to reviews (1).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ls6ksK-8E8xC"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import transformers\n",
        "from transformers import BertTokenizer, BertModel, AdamW, BertConfig\n",
        "import torch\n",
        "import tensorflow as tf"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "id": "okegOIgtD_te",
        "outputId": "be976196-1893-47ea-c51e-8928bc64ac24"
      },
      "source": [
        "df = pd.read_csv(\"reviews.csv\")\n",
        "df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userName</th>\n",
              "      <th>userImage</th>\n",
              "      <th>content</th>\n",
              "      <th>score</th>\n",
              "      <th>thumbsUpCount</th>\n",
              "      <th>reviewCreatedVersion</th>\n",
              "      <th>at</th>\n",
              "      <th>replyContent</th>\n",
              "      <th>repliedAt</th>\n",
              "      <th>sortOrder</th>\n",
              "      <th>appId</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Andrew Thomas</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14GiHd...</td>\n",
              "      <td>Update: After getting a response from the deve...</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>4.17.0.3</td>\n",
              "      <td>2020-04-05 22:25:57</td>\n",
              "      <td>According to our TOS, and the term you have ag...</td>\n",
              "      <td>2020-04-05 15:10:24</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Craig Haines</td>\n",
              "      <td>https://lh3.googleusercontent.com/-hoe0kwSJgPQ...</td>\n",
              "      <td>Used it for a fair amount of time without any ...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>4.17.0.3</td>\n",
              "      <td>2020-04-04 13:40:01</td>\n",
              "      <td>It sounds like you logged in with a different ...</td>\n",
              "      <td>2020-04-05 15:11:35</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>steven adkins</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14GiXw...</td>\n",
              "      <td>Your app sucks now!!!!! Used to be good but no...</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>4.17.0.3</td>\n",
              "      <td>2020-04-01 16:18:13</td>\n",
              "      <td>This sounds odd! We are not aware of any issue...</td>\n",
              "      <td>2020-04-02 16:05:56</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Lars Panzerbjørn</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14Gg-h...</td>\n",
              "      <td>It seems OK, but very basic. Recurring tasks n...</td>\n",
              "      <td>1</td>\n",
              "      <td>192</td>\n",
              "      <td>4.17.0.2</td>\n",
              "      <td>2020-03-12 08:17:34</td>\n",
              "      <td>We do offer this option as part of the Advance...</td>\n",
              "      <td>2020-03-15 06:20:13</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Scott Prewitt</td>\n",
              "      <td>https://lh3.googleusercontent.com/-K-X1-YsVd6U...</td>\n",
              "      <td>Absolutely worthless. This app runs a prohibit...</td>\n",
              "      <td>1</td>\n",
              "      <td>42</td>\n",
              "      <td>4.17.0.2</td>\n",
              "      <td>2020-03-14 17:41:01</td>\n",
              "      <td>We're sorry you feel this way! 90% of the app ...</td>\n",
              "      <td>2020-03-15 23:45:51</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           userName  ...      appId\n",
              "0     Andrew Thomas  ...  com.anydo\n",
              "1      Craig Haines  ...  com.anydo\n",
              "2     steven adkins  ...  com.anydo\n",
              "3  Lars Panzerbjørn  ...  com.anydo\n",
              "4     Scott Prewitt  ...  com.anydo\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoM3mWwUEzS-",
        "outputId": "ecbd6c89-6831-41a8-cb4a-9ad44e98fddb"
      },
      "source": [
        "print (\"Number of rows -\", df.shape[0])\n",
        "print (\"Number of columns -\", df.shape[1])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of rows - 15746\n",
            "Number of columns - 11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kBAP-3lFQZZ"
      },
      "source": [
        "def to_sentiment(rating):\n",
        "  rating = int(rating)\n",
        "  if rating <= 2:\n",
        "    return 0\n",
        "  elif rating == 3:\n",
        "    return 1\n",
        "  else: \n",
        "    return 2\n",
        "\n",
        "df['sentiment'] = df.score.apply(to_sentiment)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "fthcckuSFYJy",
        "outputId": "7fc75f81-75bf-4a43-f4ce-fed9660f0a13"
      },
      "source": [
        "class_names = ['negative', 'neutral', 'positive']\n",
        "ax = sns.countplot(df.sentiment)\n",
        "plt.xlabel('review sentiment')\n",
        "ax.set_xticklabels(class_names);"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEeOSOnwFhJC"
      },
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\n",
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XUiZNmXG_n1",
        "outputId": "2195d38f-92e5-4900-c5a1-64755bd55175"
      },
      "source": [
        "sentences = df.content.values\n",
        "labels = df.sentiment.values\n",
        "\n",
        "sent_lengths = []\n",
        "for s in sentences:\n",
        "    words = s.split(\" \")\n",
        "    sent_lengths.append(len(words))\n",
        "print (\"The maximum length of the input sentences - \",max(sent_lengths))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The maximum length of the input sentences -  391\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulqYIEx8PuJA"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "train, val = train_test_split(df, test_size=0.20, shuffle=True, stratify=df['sentiment'])\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_train = np.asarray(le.fit_transform(train['sentiment']))\n",
        "y_val = np.asarray(le.fit_transform(val['sentiment']))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlCOhTp0QX0X"
      },
      "source": [
        "import tqdm\n",
        "# Initialise Bert Tokenizer\n",
        "bert_tokenizer_transformer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "\n",
        "def create_input_array(df, tokenizer):\n",
        "    sentences = df.content.values\n",
        "\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    token_type_ids = []\n",
        "\n",
        "    for sent in sentences:\n",
        "        # `encode_plus` will:\n",
        "        #   (1) Tokenize the sentence.\n",
        "        #   (2) Prepend the `[CLS]` token to the start.\n",
        "        #   (3) Append the `[SEP]` token to the end.\n",
        "        #   (4) Map tokens to their IDs.\n",
        "        #   (5) Pad or truncate the sentence to `max_length`\n",
        "        #   (6) Create attention masks for [PAD] tokens.\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "            sent,  # Sentence to encode.\n",
        "            add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
        "            max_length=512,  # Pad & truncate all sentences.\n",
        "                pad_to_max_length=True,\n",
        "                return_attention_mask=True,  # Construct attn. masks.\n",
        "                return_tensors='tf',  # Return tf tensors.\n",
        "            )\n",
        "\n",
        "        # Add the encoded sentence to the list.\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "        # And its attention mask (simply differentiates padding from non-padding).\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "        token_type_ids.append(encoded_dict['token_type_ids'])\n",
        "\n",
        "    input_ids = tf.convert_to_tensor(input_ids)\n",
        "    attention_masks = tf.convert_to_tensor(attention_masks)\n",
        "    token_type_ids = tf.convert_to_tensor(token_type_ids)\n",
        "\n",
        "    return input_ids, attention_masks, token_type_ids"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u568M-IKQeCu",
        "outputId": "26c3285f-d2a2-4f16-8432-245baab8eeee"
      },
      "source": [
        "train_inputs = [create_input_array(train[:], tokenizer=tokenizer)]\n",
        "val_inputs = [create_input_array(val[:], tokenizer=tokenizer)]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2190: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Je90TCF3SCWq"
      },
      "source": [
        "def convert_inputs_to_tf_dataset(inputs,y):\n",
        "    max_seq_len = 512\n",
        "    ids = inputs[0][1]\n",
        "    masks = inputs[0][1]\n",
        "    token_types = inputs[0][2]\n",
        "\n",
        "    ids = tf.reshape(ids, (-1, max_seq_len))\n",
        "    print(\"Input ids shape: \", ids.shape)\n",
        "    masks = tf.reshape(masks, (-1, max_seq_len))\n",
        "    print(\"Input Masks shape: \", masks.shape)\n",
        "    token_types = tf.reshape(token_types, (-1, max_seq_len))\n",
        "    print(\"Token type ids shape: \", token_types.shape)\n",
        "\n",
        "    ids=ids.numpy()\n",
        "    masks = masks.numpy()\n",
        "    token_types = token_types.numpy()\n",
        "\n",
        "    return [ids, masks, token_types, y]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlWNdpXdU4P1",
        "outputId": "a175861f-1268-4193-c24a-b391a0f4604d"
      },
      "source": [
        "training_df = convert_inputs_to_tf_dataset(train_inputs[0], y_train[0])\n",
        "type(train_inputs[0])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input ids shape:  (1, 512)\n",
            "Input Masks shape:  (1, 512)\n",
            "Token type ids shape:  (1, 512)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tuple"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDM-45XbSbTA",
        "outputId": "eed8fbfe-136f-4a3d-bff7-b55d7d7e1858"
      },
      "source": [
        "from transformers import TFBertForSequenceClassification\n",
        "import tensorflow as tf\n",
        "max_seq_len = 768\n",
        "n_classes = 3\n",
        "\n",
        "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', trainable=True, num_labels=n_classes)\n",
        "\n",
        "input_ids_layer = tf.keras.layers.Input(shape=(max_seq_len, ), dtype=np.int32)\n",
        "input_mask_layer = tf.keras.layers.Input(shape=(max_seq_len, ), dtype=np.int32)\n",
        "input_token_type_layer = tf.keras.layers.Input(shape=(max_seq_len,), dtype=np.int32)\n",
        "\n",
        "bert_layer = model([input_ids_layer, input_mask_layer, input_token_type_layer])[0]\n",
        "flat_layer = tf.keras.layers.Flatten()(bert_layer)\n",
        "dropout= tf.keras.layers.Dropout(0.3)(flat_layer)\n",
        "dense_output = tf.keras.layers.Dense(n_classes, activation='softmax')(dropout)\n",
        "\n",
        "model_ = tf.keras.Model(inputs=[input_ids_layer, input_mask_layer, input_token_type_layer], outputs=dense_output)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
        "print (model.summary())\n",
        "model.compile(optimizer='adam', loss=loss, metrics=[metric])\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "Model: \"tf_bert_for_sequence_classification_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bert (TFBertMainLayer)       multiple                  109482240 \n",
            "_________________________________________________________________\n",
            "dropout_458 (Dropout)        multiple                  0         \n",
            "_________________________________________________________________\n",
            "classifier (Dense)           multiple                  2307      \n",
            "=================================================================\n",
            "Total params: 109,484,547\n",
            "Trainable params: 109,484,547\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        },
        "id": "M2uge-EDYw_V",
        "outputId": "beb7868e-7c46-44e1-ad5c-2a87a27bb8b0"
      },
      "source": [
        "model.fit(train_inputs, y_train, epochs=1, batch_size = 32,verbose=1)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-b5043c4a424e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    759\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 760\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3067\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3306\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3307\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3308\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3309\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3310\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_tf_bert.py:1440 call  *\n        outputs = self.bert(\n    /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_tf_bert.py:645 call  *\n        embedding_output = self.embeddings(\n    /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_tf_bert.py:202 call  *\n        final_embeddings = self.LayerNorm(inputs=final_embeddings)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py:1037 __call__  **\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/keras/layers/normalization/layer_normalization.py:285 call\n        scale, offset = _broadcast(self.gamma), _broadcast(self.beta)\n    /usr/local/lib/python3.7/dist-packages/keras/layers/normalization/layer_normalization.py:272 _broadcast\n        return tf.reshape(v, broadcast_shape)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:196 reshape\n        result = gen_array_ops.reshape(tensor, shape, name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py:8404 reshape\n        \"Reshape\", tensor=tensor, shape=shape, name=name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:750 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py:601 _create_op_internal\n        compute_device)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py:3569 _create_op_internal\n        op_def=op_def)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py:2042 __init__\n        control_input_ops, op_def)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py:1883 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Cannot reshape a tensor with 768 elements to shape [1,1,512,1] (512 elements) for '{{node tf_bert_for_sequence_classification_11/bert/embeddings/LayerNorm/Reshape}} = Reshape[T=DT_FLOAT, Tshape=DT_INT32](tf_bert_for_sequence_classification_11/bert/embeddings/LayerNorm/Reshape/ReadVariableOp, tf_bert_for_sequence_classification_11/bert/embeddings/LayerNorm/Reshape/shape)' with input shapes: [768], [4] and with input tensors computed as partial shapes: input[1] = [1,1,512,1].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMtUv1wfMK36"
      },
      "source": [
        "# # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "# input_ids = []\n",
        "# attention_masks = []\n",
        "# token_type_ids = []\n",
        "\n",
        "# # For every sentence...\n",
        "# for sent in sentences:\n",
        "#     # `encode_plus` will:\n",
        "#     #   (1) Tokenize the sentence.\n",
        "#     #   (2) Prepend the `[CLS]` token to the start.\n",
        "#     #   (3) Append the `[SEP]` token to the end.\n",
        "#     #   (4) Map tokens to their IDs.\n",
        "#     #   (5) Pad or truncate the sentence to `max_length`\n",
        "#     #   (6) Create attention masks for [PAD] tokens.\n",
        "#     encoded_dict = tokenizer.encode_plus(\n",
        "#                         sent,                      # Sentence to encode.\n",
        "#                         add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "#                         max_length = 512,           # Pad & truncate all sentences.\n",
        "#                         pad_to_max_length = True,\n",
        "#                         return_attention_mask = True,   # Construct attn. masks.\n",
        "#                         return_tensors = 'pt',     # Return pytorch tensors.\n",
        "#                    )\n",
        "#     input_ids.append(encoded_dict['input_ids'])\n",
        "#     # And its attention mask (simply differentiates padding from non-padding).\n",
        "#     attention_masks.append(encoded_dict['attention_mask'])\n",
        "#     token_type_ids.append(encoded_dict['token_type_ids'])\n",
        "\n",
        "# input_ids = tf.convert_to_tensor(input_ids)\n",
        "# attention_masks = tf.convert_to_tensor(attention_masks)\n",
        "# token_type_ids = tf.convert_to_tensor(token_type_ids)\n",
        "# print (\"Completed the pre-processing\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vLt05JmMsVU"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "print (\"Train Size -\", train_size)\n",
        "print (\"Test Size - \", val_size)\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHvk3aVHN2kv"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIIL5hQIRbXM"
      },
      "source": [
        "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beKTFeJnXK0V"
      },
      "source": [
        "optimizer = AdamW(bert_model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoAsAz0nYclx"
      },
      "source": [
        "class SentimentClassifier(nn.Module):\n",
        "  def __init__(self, n_classes):\n",
        "    super(SentimentClassifier, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    _, pooled_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjHWPaXiZCAl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}